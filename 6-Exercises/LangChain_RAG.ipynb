{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696dc77e",
   "metadata": {},
   "source": [
    "### LangChain + RAG Exercise\n",
    "\n",
    "This workbook shows the use of LangChain with RAG ( Retrieval Augmentation Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Import environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Google AI Package\n",
    "import google.generativeai\n",
    "\n",
    "#Import glob module\n",
    "import glob\n",
    "\n",
    "# Import modules and packages from langChain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables Declaration\n",
    "\n",
    "# Model of Google Gemini used\n",
    "MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# Name of Vector Data Store\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33968d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environement Variables\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# load Google Api Key from .env file\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# Authenticate to Python SDK for future requests\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23ef7c",
   "metadata": {},
   "source": [
    "## LangChain Workflow\n",
    "\n",
    "In this notebook, we will demonstrate the LangChain workflow step by step.\n",
    "\n",
    "### Step 1: Data Ingestion\n",
    "\n",
    "In this section, we will demonstrate how to load a particular dataset from a specific data source (our pre defined knowledge base) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bcb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# Configure the encoding (Optional)\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "# Document object generated when dataset is loaded \n",
    "documents = []\n",
    "\n",
    "# Loop through all folders in knowledge base\n",
    "for folder in folders:\n",
    "    \n",
    "    # Retrieve doc type of folder\n",
    "    doc_type = os.path.basename(folder)\n",
    "\n",
    "    # Load Markdown files from knowledge base directory. Each file is processed by TextLoader, converted into a Document object.\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "\n",
    "    # Execute the document loading process\n",
    "    folder_docs = loader.load()\n",
    "\n",
    "    # For each Document Object, append doc_type to metadata\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e00c4d",
   "metadata": {},
   "source": [
    "### Step 2. Data Transformation\n",
    "\n",
    "The following section describes how to break down the Document Objects from step 1 into small text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe933d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RecursiveCharacterTextSplitter as it is better suited for generic texts than CharacterTextSplitter.\n",
    "# No need to specify where to chunk data as RecursiveCharacterTextSplitter chunks data on \\n,\"\", empty spaces\n",
    "\n",
    "# chunk_size = specify the size of chunks\n",
    "# chunk_overlap = specify the number of characters to overlap in consecutive chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# generate chunks by splitting Document Object obtained from step 1\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3e7f2",
   "metadata": {},
   "source": [
    "### Step 3. Embeddings\n",
    "\n",
    "This section demonstrates how to convert text chunks obtained from Step 2 into vectors ( Vectorize Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a843da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using Google Gemini Embedding\n",
    "\n",
    "# mode = specify which model to use\n",
    "# dimensions = specify the number of dimensions to embed the vectors\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", dimensions=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d523eb7",
   "metadata": {},
   "source": [
    "### Step 4. Store in Vector DataStore\n",
    "\n",
    "This section demonstrated the final step in the LangChain workflow where each vectors are saved in a vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f91bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "\n",
    "total_vectors = vectorstore.index.ntotal\n",
    "dimensions = vectorstore.index.d\n",
    "\n",
    "print(f\"There are {total_vectors} vectors with {dimensions:,} dimensions in the vector store\")\n",
    "\n",
    "# Save vectorstore locally\n",
    "vectorstore.save_local(db_name)\n",
    "\n",
    "# Reload Vector Store Database\n",
    "vectorstore=FAISS.load_local(db_name,embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503067cd",
   "metadata": {},
   "source": [
    "### Visualise Vector Store\n",
    "\n",
    "The following diagram will help to try to visualise the vector Store in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework\n",
    "\n",
    "vectors = []\n",
    "documents = []\n",
    "doc_types = []\n",
    "colors = []\n",
    "color_map = {'products':'blue', 'employees':'green', 'contracts':'red', 'company':'orange'}\n",
    "\n",
    "for i in range(total_vectors):\n",
    "    vectors.append(vectorstore.index.reconstruct(i))\n",
    "    doc_id = vectorstore.index_to_docstore_id[i]\n",
    "    document = vectorstore.docstore.search(doc_id)\n",
    "    documents.append(document.page_content)\n",
    "    doc_type = document.metadata['doc_type']\n",
    "    doc_types.append(doc_type)\n",
    "    colors.append(color_map[doc_type])\n",
    "    \n",
    "vectors = np.array(vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eee8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D FAISS Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda8548",
   "metadata": {},
   "source": [
    "## Creation of RAG Pipeline\n",
    "\n",
    "The following section will now demonstrate how to create a RAG pipeline with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a4a2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create a new Chat with ChatGoogleGenerativeAI\n",
    "\n",
    "# model = Specify the model of LLM used\n",
    "# temperature = Controls randomness (higher = more creative, lower = more deterministic)\n",
    "llm = ChatGoogleGenerativeAI(model=MODEL, temperature=0.7)\n",
    "\n",
    "# 2. create a chat memory component in LangChain, allowing your chatbot or agent to remember previous messages in a conversation.\n",
    "\n",
    "# memory_key = The key under which memory will be passed into the prompt\n",
    "# return_messages = returns structured messages (HumanMessage, AIMessage) instead of just strings\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# 3. the retriever is an abstraction over the VectorStore that will be used during RAG to fetch the most relevant document chunks for a query.\n",
    "\n",
    "# search_kwargs = Returns the top 25 most similar chunks for a given input query\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. putting it together: set up the conversation chain with the GPT 4o-mini LLM, the vector store and memory\n",
    "\n",
    "# callbacks=[StdOutCallbackHandler()] - Optional to view all the call backs\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0716676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "# HR Record\n",
      "\n",
      "# Alex Chen\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth:** March 15, 1990  \n",
      "- **Job Title:** Backend Software Engineer  \n",
      "- **Location:** San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **April 2020:** Joined Insurellm as a Junior Backend Developer. Focused on building APIs to enhance customer data security.\n",
      "- **October 2021:** Promoted to Backend Software Engineer. Took on leadership for a key project developing a microservices architecture to support the company's growing platform.\n",
      "- **March 2023:** Awarded the title of Senior Backend Software Engineer due to exemplary performance in scaling backend services, reducing downtime by 30% over six months.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:**  \n",
      "  - Completed onboarding successfully.  \n",
      "  - Met expectations in delivering project milestones.  \n",
      "  - Received positive feedback from the team leads.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:**  \n",
      "  - Completed onboarding successfully.  \n",
      "  - Met expectations in delivering project milestones.  \n",
      "  - Received positive feedback from the team leads.\n",
      "\n",
      "- **2021:**  \n",
      "  - Achieved a 95% success rate in project delivery timelines.  \n",
      "  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \n",
      "\n",
      "- **2022:**  \n",
      "  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \n",
      "  - Conducted training sessions for junior developers, fostering knowledge sharing.  \n",
      "\n",
      "- **2023:**  \n",
      "  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \n",
      "  - Contributed to the company’s transition to a cloud-based infrastructure.  \n",
      "  - Received an overall performance rating of 4.8/5.\n",
      "\n",
      "## Compensation History\n",
      "- **2015**: $150,000 base salary + Significant equity stake  \n",
      "- **2016**: $160,000 base salary + Equity increase  \n",
      "- **2017**: $150,000 base salary + Decrease in bonus due to performance  \n",
      "- **2018**: $180,000 base salary + performance bonus of $30,000  \n",
      "- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \n",
      "- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \n",
      "- **2021**: $200,000 base salary + performance bonus of $50,000  \n",
      "- **2022**: $210,000 base salary + retention bonus  \n",
      "- **2023**: $225,000 base salary + $75,000 performance bonus\n",
      "\n",
      "**Insurellm, Inc.**  \n",
      "_____________________________  \n",
      "Authorized Signature   \n",
      "Date: ___________________  \n",
      "\n",
      "**Apex Reinsurance**  \n",
      "_____________________________  \n",
      "Authorized Signature  \n",
      "Date: ___________________\n",
      "Human: How many employees are there in the company based on the number of records present in employee folder?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Answer: This document only contains information for one employee, Alex Chen.  Therefore, based on this document alone, we cannot determine the total number of employees at the company.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you describe Deloitte in a few sentences\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "# query = \"Who received the prestigious IIOTY award in 2023?\"\n",
    "# result = conversation_chain.invoke({\"question\": query})\n",
    "# answer = result[\"answer\"]\n",
    "# print(\"\\nAnswer:\", answer)\n",
    "\n",
    "# query = \"How many employees are there in the company based on the number of records present in employee folder?\"\n",
    "# result = conversation_chain.invoke({\"question\": query})\n",
    "# answer = result[\"answer\"]\n",
    "# print(\"\\nAnswer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
